apply_lr_decay: true
checkpoint_cutting: 1.0
cutting: 1.0
early_stop_params:
  min_delta: 1.0e-06
  mode: min
  monitor: val_loss_E
  patience: 10
loss_E_name: MyLoss
loss_sigma_name: null
lr: 0.0002 <keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay object
  at 0x7f05005e0520>
lr_decay: 0.001
lr_sigma: 0.0002 0.0002 <keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay
  object at 0x7f05005e0520>
metrics: '[<nn.metrics.nlogE_MAE object at 0x7f05005e06d0>, <nn.metrics.nSigmaMAE
  object at 0x7f0500621850>]'
num_of_epochs: 100
optimizer: <class 'keras.optimizers.optimizer_experimental.adam.Adam'>
verbose: false
verbose_cutting: 50.0
weighted_metrics: '[<nn.metrics.nlogE_MAE object at 0x7f0500582e50>, <nn.metrics.nSigmaMAE
  object at 0x7f050058f910>]'
