apply_lr_decay: true
checkpoint_cutting: 1.0
cutting: 1.0
early_stop_params:
  min_delta: 1.0e-06
  mode: min
  monitor: val_loss_E
  patience: 10
loss_E_name: MyLoss
loss_sigma_name: null
lr: 0.0001 <keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay object
  at 0x7f09bc5c2040>
lr_decay: 0.001
lr_sigma: 0.0001 0.0001 <keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay
  object at 0x7f09bc5c2040>
metrics: '[<nn.metrics.nlogE_MAE object at 0x7f09c80558b0>, <nn.metrics.nSigmaMAE
  object at 0x7f09bc546700>]'
num_of_epochs: 100
optimizer: <class 'keras.optimizers.optimizer_experimental.adam.Adam'>
verbose: false
verbose_cutting: 50.0
weighted_metrics: '[<nn.metrics.nlogE_MAE object at 0x7f09c80a2d60>, <nn.metrics.nSigmaMAE
  object at 0x7f09bc5de0d0>]'
