apply_lr_decay: true
checkpoint_cutting: 1.0
cutting: 1.0
early_stop_params:
  min_delta: 1.0e-06
  mode: min
  monitor: val_loss_E
  patience: 10
loss_E_name: MyLoss
loss_sigma_name: null
lr: 0.0001 <keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay object
  at 0x7fdf903c43d0>
lr_decay: 0.001
lr_sigma: 0.0001 0.0001 <keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay
  object at 0x7fdf903c43d0>
metrics: '[<nn.metrics.nlogE_MAE object at 0x7fdfa003f460>, <nn.metrics.nSigmaMAE
  object at 0x7fdf902fd0a0>]'
num_of_epochs: 100
optimizer: <class 'keras.optimizers.optimizer_experimental.adam.Adam'>
verbose: false
verbose_cutting: 50.0
weighted_metrics: '[<nn.metrics.nlogE_MAE object at 0x7fdf903047c0>, <nn.metrics.nSigmaMAE
  object at 0x7fdf903140a0>]'
