apply_lr_decay: true
checkpoint_cutting: 1.0
cutting: 1.0
early_stop_params:
  min_delta: 1.0e-06
  mode: min
  monitor: val_loss_E
  patience: 20
loss_E_name: MyLoss
loss_sigma_name: null
lr: 0.001 <keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay object
  at 0x7ff7a6a85de0>
lr_decay: 0.05
lr_sigma: 0.001 0.001 <keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay
  object at 0x7ff7a6a85de0>
metrics: '[<NNBlock.nn.metrics.nlogE_MAE object at 0x7ff7a6a852a0>, <NNBlock.nn.metrics.nSigmaAbsMAE
  object at 0x7ff7a6a859f0>]'
num_of_epochs: 300
optimizer: <class 'keras.optimizers.optimizer_experimental.adam.Adam'>
verbose: false
verbose_cutting: 50.0
weighted_metrics: '[<NNBlock.nn.metrics.nlogE_MAE object at 0x7ff7a6b1e8f0>, <NNBlock.nn.metrics.nSigmaAbsMAE
  object at 0x7ff7a6b1e290>]'
